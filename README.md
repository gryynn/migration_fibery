# ğŸš€ Migration Fibery â†’ Supabase/PostgreSQL

**Outil de migration simple** pour transformer vos exports CSV Fibery en SQL PostgreSQL/Supabase avec prÃ©servation automatique des relations, types de donnÃ©es et structures.

> **ğŸ¯ Cas d'usage parfait :** Vous avez dÃ©jÃ  exportÃ© vos bases de donnÃ©es Fibery en CSV et voulez les importer dans Supabase !

---

## ğŸ“‹ Table des matiÃ¨res

- [ğŸš€ Migration Fibery â†’ Supabase/PostgreSQL](#-migration-fibery--supabasepostgresql)
  - [ğŸ“‹ Table des matiÃ¨res](#-table-des-matiÃ¨res)
  - [âœ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
  - [ğŸ¯ PrÃ©requis](#-prÃ©requis)
  - [ğŸ“¦ Installation](#-installation)
  - [âš¡ DÃ©marrage rapide](#-dÃ©marrage-rapide)
  - [ğŸ”§ Configuration](#-configuration)
  - [ğŸ“Š Utilisation Ã©tape par Ã©tape](#-utilisation-Ã©tape-par-Ã©tape)
  - [ğŸ—‚ï¸ Structure des fichiers](#ï¸-structure-des-fichiers)
  - [ğŸ” Types de donnÃ©es](#-types-de-donnÃ©es)
  - [ğŸ”— Relations automatiques](#-relations-automatiques)
  - [ğŸ› DÃ©pannage](#-dÃ©pannage)
  - [ğŸ—ï¸ Architecture](#ï¸-architecture)
  - [ğŸ“ˆ Performance](#-performance)
  - [ğŸ”’ SÃ©curitÃ©](#-sÃ©curitÃ©)
  - [ğŸ¤ Support](#-support)

---

## âœ¨ FonctionnalitÃ©s

### âœ… **Migration complÃ¨te**
- **Analyse automatique** des structures de donnÃ©es Fibery
- **DÃ©tection des types** PostgreSQL (UUID, INTEGER, BOOLEAN, etc.)
- **PrÃ©servation des IDs** Fibery comme clÃ©s primaires
- **Batch processing** pour les gros volumes de donnÃ©es

### âœ… **Relations intelligentes**
- **DÃ©tection automatique** des relations many-to-many
- **CrÃ©ation des tables de jonction** avec contraintes
- **Index automatiques** pour les performances
- **Validation des rÃ©fÃ©rences** avant insertion

### âœ… **FacilitÃ© d'utilisation**
- **Configuration simple** via variables en haut des fichiers
- **Messages explicatifs** pendant l'exÃ©cution
- **Fichiers SQL prÃªts Ã  l'emploi** pour Supabase
- **Mode DRY-RUN** pour tester sans risque

### âœ… **Robustesse**
- **Gestion des erreurs** avec retry automatique
- **Validation des donnÃ©es** avant insertion
- **Ã‰chappement SQL** automatique
- **Support UTF-8** complet

---

## ğŸ¯ PrÃ©requis

### ğŸ“‹ **Avant de commencer**
- âœ… **Exports CSV Fibery** (dÃ©jÃ  tÃ©lÃ©chargÃ©s depuis Fibery)
- âœ… **Projet Supabase** crÃ©Ã© (pour copier-coller le SQL)
- âœ… **Node.js** 16+ installÃ© sur votre machine

### ğŸ“ **Structure des fichiers attendue**
```
Important/                          # Dossier de votre export Fibery
â”œâ”€â”€ Actionalisation-Dopa/
â”‚   â””â”€â”€ Actionalisation-Dopa.csv    # Un CSV par base de donnÃ©es
â”œâ”€â”€ PSM-Centres d'intÃ©rÃªt/
â”‚   â””â”€â”€ PSM-Centres d'intÃ©rÃªt.csv
â””â”€â”€ Bibliotheque-Auteurs/
    â””â”€â”€ Bibliotheque-Auteurs.csv
```

### ğŸ—„ï¸ **AccÃ¨s Supabase**
- **SQL Editor** dans votre projet Supabase (pour copier-coller)
- **Service Role Key** uniquement si vous voulez automatiser plus tard

---

## ğŸ“¦ Installation

```bash
# 1. Cloner le projet
git clone https://github.com/gryynn/migration_fibery.git
cd migration_fibery

# 2. Installer les dÃ©pendances
npm install

# 3. Configurer les chemins (dans le code)
# Ã‰diter csv-to-sql-migrator.js et create-relations.js
# Modifier la ligne : importantDir avec votre chemin vers le dossier Important
```

---

## âš¡ DÃ©marrage rapide

### **Ã‰tape 1 : Configuration**
Modifiez le chemin dans les scripts :
```javascript
// Dans csv-to-sql-migrator.js et create-relations.js
const CONFIG = {
  importantDir: 'C:\\Users\\martin\\Downloads\\mon-export\\Important',  // â† Votre chemin
  schema: 'psm_root',  // Nom du schÃ©ma PostgreSQL
  batchSize: 100       // Lignes par INSERT (ajustez selon vos donnÃ©es)
};
```

### **Ã‰tape 2 : Migration**
```bash
# 1. GÃ©nÃ©rer le SQL des tables
node csv-to-sql-migrator.js

# 2. GÃ©nÃ©rer le SQL des relations
node create-relations.js
```

### **Ã‰tape 3 : Import dans Supabase**
1. Ouvrez **Supabase SQL Editor** dans votre projet
2. Copiez-collez le contenu de `migration-complete.sql`
3. Cliquez **"Run"** pour crÃ©er les tables
4. Copiez-collez le contenu de `relations-complete.sql`
5. Cliquez **"Run"** pour crÃ©er les relations

**ğŸ‰ Vos donnÃ©es Fibery sont maintenant dans Supabase !**

---

## ğŸ”§ Configuration

### **Variables principales**

| Variable | Description | Exemple |
|----------|-------------|---------|
| `importantDir` | Chemin vers le dossier Important | `C:\Users\...\Important` |
| `schema` | Nom du schÃ©ma PostgreSQL | `psm_root` |
| `batchSize` | Lignes par INSERT | `100` (sÃ»r) Ã  `1000` (rapide) |

### **Configuration simple**

Modifiez seulement ces lignes dans les deux scripts :

```javascript
// csv-to-sql-migrator.js et create-relations.js
const CONFIG = {
  importantDir: 'C:\\Users\\martin\\Downloads\\mon-export\\Important',  // â† CHANGEZ CE CHEMIN
  schema: 'psm_root',  // â† CHANGEZ si vous voulez un autre nom de schÃ©ma
  batchSize: 100      // â† AJUSTEZ selon la taille de vos donnÃ©es
};
```

**ğŸ’¡ Pas de fichier .env, pas de clÃ©s API, juste modifier le chemin !**

---

## ğŸ“Š Utilisation Ã©tape par Ã©tape

### **Phase 1 : Analyse (csv-to-sql-migrator.js)**

```bash
node csv-to-sql-migrator.js
```

**Ce script :**
1. ğŸ” **Analyse** tous les CSV dans le dossier Important
2. ğŸ”® **DÃ©tecte** les types PostgreSQL automatiquement
3. ğŸ“ **GÃ©nÃ¨re** `migration-complete.sql` avec :
   - `CREATE TABLE` pour chaque base
   - `INSERT` par batches
   - Commentaires explicatifs

### **Phase 2 : Relations (create-relations.js)**

```bash
node create-relations.js
```

**Ce script :**
1. ğŸ” **DÃ©tecte** les colonnes de relations (avec virgules)
2. ğŸ¯ **Devine** les tables cibles automatiquement
3. ğŸ”— **GÃ©nÃ¨re** `relations-complete.sql` avec :
   - Tables de jonction many-to-many
   - ClÃ©s Ã©trangÃ¨res avec contraintes
   - Index pour les performances

### **Phase 3 : ExÃ©cution SQL**

1. **Supabase SQL Editor** â†’ Nouveau query
2. **Copier-coller** `migration-complete.sql`
3. **Run** â†’ Tables crÃ©Ã©es
4. **Copier-coller** `relations-complete.sql`
5. **Run** â†’ Relations crÃ©Ã©es

---

## ğŸ—‚ï¸ Structure des fichiers

### **Fichiers gÃ©nÃ©rÃ©s**

```
migration-complete.sql    # Tables et donnÃ©es principales
relations-complete.sql    # Relations many-to-many
```

### **Structure PostgreSQL crÃ©Ã©e**

```
psm_root/
â”œâ”€â”€ actionalisation_dopa/           # Table principale
â”‚   â”œâ”€â”€ id (UUID, Primary Key)
â”‚   â”œâ”€â”€ name (TEXT)
â”‚   â”œâ”€â”€ psm_centres_dinterets (TEXT)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ psm_centres_dinteret/          # Table liÃ©e
â”‚   â””â”€â”€ id (UUID, Primary Key)
â””â”€â”€ actionalisation_dopa_psm_centres_dinteret/  # Table de jonction
    â”œâ”€â”€ actionalisation_dopa_id (UUID, FK)
    â”œâ”€â”€ psm_centres_dinteret_id (UUID, FK)
    â””â”€â”€ PRIMARY KEY (dopa_id, centres_id)
```

---

## ğŸ” Types de donnÃ©es

### **DÃ©tection automatique**

| Type Fibery | Type PostgreSQL | Exemple |
|-------------|-----------------|---------|
| ID | `UUID` | `d47ec620-2190-11ef-910c-f1df4955273f` |
| Nombre | `INTEGER` | `123`, `-456` |
| DÃ©cimal | `NUMERIC(12,2)` | `123.45` |
| BoolÃ©en | `BOOLEAN` | `true`, `false`, `1`, `0` |
| Date | `DATE` | `2024-06-03` |
| Date/Heure | `TIMESTAMPTZ` | `2024-06-03T10:05:39.625Z` |
| Texte | `TEXT` | `Tout le reste` |

### **Relations dÃ©tectÃ©es**

| Format | Exemple | RÃ©sultat |
|--------|---------|----------|
| Liste | `"A,B,C"` | 3 relations crÃ©Ã©es |
| Nom Fibery | `"PSM-Insights"` | Lien vers table `psm_insights` |
| RÃ©fÃ©rence | `"user_id"` | Lien vers table `user` |

---

## ğŸ”— Relations automatiques

### **Comment Ã§a marche**

1. **Analyse** : Le script scanne toutes les colonnes
2. **DÃ©tection** : Cherche les virgules et patterns de noms
3. **Association** : Devine les tables cibles
4. **CrÃ©ation** : GÃ©nÃ¨re les tables de jonction

### **Exemple concret**

**DonnÃ©es Fibery :**
```
Table: Actionalisation-Dopa
- id: abc-123
- name: "Duo Lingo"
- PSM-Centres d'intÃ©rÃªt: "DÃ©veloppement personnel,Communication"

Table: PSM-Centres d'intÃ©rÃªt
- id: def-456
- name: "DÃ©veloppement personnel"
- id: ghi-789
- name: "Communication"
```

**RÃ©sultat PostgreSQL :**
```sql
-- Table de jonction crÃ©Ã©e automatiquement
CREATE TABLE psm_root.actionalisation_dopa_psm_centres_dinteret (
  actionalisation_dopa_id UUID REFERENCES psm_root.actionalisation_dopa(id),
  psm_centres_dinteret_id UUID REFERENCES psm_root.psm_centres_dinteret(id),
  PRIMARY KEY (actionalisation_dopa_id, psm_centres_dinteret_id)
);

-- DonnÃ©es insÃ©rÃ©es
INSERT INTO psm_root.actionalisation_dopa_psm_centres_dinteret
VALUES ('abc-123', 'def-456'), ('abc-123', 'ghi-789');
```

---

## ğŸ› DÃ©pannage

### **ProblÃ¨mes courants**

#### âŒ **"Dossier introuvable"**
```bash
# VÃ©rifiez le chemin
console.log(CONFIG.importantDir);
// Doit pointer vers le dossier Important de votre export
```

#### âŒ **"Aucune relation dÃ©tectÃ©e"**
- VÃ©rifiez que vos colonnes contiennent des virgules
- Les noms de colonnes correspondent-ils aux noms de tables ?

#### âŒ **"Type UUID invalide"**
- Supabase attend des UUID valides
- VÃ©rifiez que vos IDs Fibery sont au bon format

#### âŒ **"Foreign key violation"**
- ExÃ©cutez d'abord `migration-complete.sql`
- Puis `relations-complete.sql`

### **Logs de dÃ©bogage**

```bash
# Mode verbeux
console.log(`Traitement: ${dbName}`);
console.log(`Colonnes: ${headers.length}`);
console.log(`Lignes: ${rows.length}`);
```

### **Validation post-migration**

```sql
-- Compter les tables
SELECT COUNT(*) FROM information_schema.tables
WHERE table_schema = 'psm_root';

-- VÃ©rifier les relations
SELECT
  schemaname,
  tablename,
  n_live_tup as row_count
FROM pg_stat_user_tables
WHERE schemaname = 'psm_root'
ORDER BY n_live_tup DESC;
```

---

## ğŸ—ï¸ Architecture

```
ğŸ“ migration-fibery-supabase/
â”œâ”€â”€ ğŸ“„ csv-to-sql-migrator.js     # Migration des tables
â”œâ”€â”€ ğŸ“„ create-relations.js        # DÃ©tection des relations
â”œâ”€â”€ ğŸ“„ migration-complete.sql     # SQL gÃ©nÃ©rÃ© (tables)
â”œâ”€â”€ ğŸ“„ relations-complete.sql     # SQL gÃ©nÃ©rÃ© (relations)
â”œâ”€â”€ ğŸ“„ README.md                  # Ce guide
â””â”€â”€ ğŸ“„ package.json               # DÃ©pendances
```

### **Flux de donnÃ©es**

```
Fibery CSV â†’ Analyse â†’ Types PostgreSQL â†’ Tables SQL â†’ Supabase
    â†“
Relations CSV â†’ DÃ©tection â†’ Tables jonction â†’ Relations SQL â†’ Supabase
```

---

## ğŸ“ˆ Performance

### **Temps de migration**

| Volume | Temps approx. | Configuration |
|--------|---------------|---------------|
| 10 tables, 1K lignes | ~30 secondes | batchSize: 100 |
| 50 tables, 10K lignes | ~3 minutes | batchSize: 500 |
| 100 tables, 50K lignes | ~15 minutes | batchSize: 1000 |

### **Optimisation**

```javascript
// Migration rapide (peut Ã©chouer avec gros volumes)
batchSize: 1000,
retryDelay: 500

// Migration sÃ»re (recommandÃ©)
batchSize: 100,
retryDelay: 2000
```

---

## ğŸ”’ SÃ©curitÃ©

### **Bonnes pratiques**

- âœ… **Backup de vos CSV** avant de commencer
- âœ… **Projet Supabase de test** pour valider d'abord
- âœ… **Petits tests** avant la migration complÃ¨te
- âœ… **VÃ©rification** des rÃ©sultats dans Supabase aprÃ¨s import

---

## ğŸ¤ Support

### **Documentation**

- ğŸ“– **README.md** - Guide complet
- ğŸ’¬ **Code commentÃ©** - Explications dans le code
- ğŸ” **Logs dÃ©taillÃ©s** - Messages pendant l'exÃ©cution

### **Aide**

1. **Logs** : VÃ©rifiez la console pour les messages d'erreur
2. **Fichiers** : Examinez le SQL gÃ©nÃ©rÃ©
3. **Tests** : Utilisez de petits Ã©chantillons d'abord

### **Ã‰volution**

Ce projet est en amÃ©lioration continue. N'hÃ©sitez pas Ã  :
- ğŸ“ Signaler des bugs
- ğŸ’¡ Proposer des amÃ©liorations
- ğŸ”„ Contribuer au code

---

## ğŸ‰ SuccÃ¨s !

AprÃ¨s migration, vous devriez avoir :
- âœ… Toutes vos tables Fibery en PostgreSQL
- âœ… Relations many-to-many prÃ©servÃ©es
- âœ… Types de donnÃ©es optimisÃ©s
- âœ… Index pour les performances
- âœ… DonnÃ©es prÃªtes pour vos applications

**Prochaines Ã©tapes :**
1. **Connectez** vos applications Ã  Supabase
2. **Remplacez** les queries Fibery par du SQL
3. **Optimisez** les queries avec les index crÃ©Ã©s
4. **Archivez** votre workspace Fibery

---

**âœ¨ Migration rÃ©ussie ! Vos donnÃ©es Fibery sont maintenant dans PostgreSQL !**
