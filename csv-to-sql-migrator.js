#!/usr/bin/env node
/**
 * ========================================================================
 * MIGRATEUR CSV ‚Üí SQL - Fibery vers Supabase/PostgreSQL
 * ========================================================================
 *
 * GUIDE D'UTILISATION RAPIDE :
 * ===========================
 *
 * 1. PR√âPARATION :
 *    - Exportez vos bases Fibery en CSV (format Excel)
 *    - Placez les fichiers dans un dossier "Important"
 *    - Chaque sous-dossier = une base de donn√©es Fibery
 *    - Chaque CSV = une table dans cette base
 *
 * 2. CONFIGURATION :
 *    - Modifiez importantDir avec le chemin vers votre dossier Important
 *    - Ajustez schema, batchSize selon vos besoins
 *    - Le script g√©n√®re automatiquement les types PostgreSQL
 *
 * 3. EX√âCUTION :
 *    node csv-to-sql-migrator.js
 *
 * 4. R√âSULTAT :
 *    - Fichier migration-complete.sql g√©n√©r√©
 *    - Ex√©cutez-le dans Supabase SQL Editor
 *
 * EXEMPLE DE STRUCTURE DE DOSSIERS ATTENDUE :
 * ===========================================
 * Important/
 *   ‚îú‚îÄ‚îÄ Actionalisation-Dopa/
 *   ‚îÇ   ‚îî‚îÄ‚îÄ Actionalisation-Dopa.csv
 *   ‚îú‚îÄ‚îÄ PSM-Centres d'int√©r√™t/
 *   ‚îÇ   ‚îî‚îÄ‚îÄ PSM-Centres d'int√©r√™t.csv
 *   ‚îî‚îÄ‚îÄ Bibliotheque-Auteurs/
 *       ‚îî‚îÄ‚îÄ Bibliotheque-Auteurs.csv
 *
 * TYPES DE DONN√âES DETECT√âS AUTOMATIQUEMENT :
 * ============================================
 * - UUID : pour les IDs Fibery (format standard UUID)
 * - INTEGER : nombres entiers
 * - NUMERIC(12,2) : nombres d√©cimaux
 * - BOOLEAN : true/false, 1/0, yes/no
 * - DATE : format YYYY-MM-DD
 * - TIMESTAMPTZ : dates avec heure (ISO 8601)
 * - TEXT : texte par d√©faut
 */

const fs = require('fs');
const path = require('path');

// ============================================
// CONFIGURATION - √Ä MODIFIER SELON VOS BESOINS
// ============================================
const CONFIG = {
  /**
   * üìÅ Chemin vers le dossier "Important" de votre export Fibery
   * =======================================================
   * Exemple Windows: 'C:\\Users\\nom\\Downloads\\monfichier.fibery.io_20251201\\Important'
   * Exemple Mac/Linux: '/Users/nom/Downloads/monfichier.fibery.io_20251201/Important'
   */
  importantDir: 'C:\\Users\\marti\\Downloads\\martunvert.fibery.io_20251023104856287\\Important',

  /**
   * üìÑ Nom du fichier SQL qui sera g√©n√©r√©
   */
  outputSQL: './migration-complete.sql',

  /**
   * üóÇÔ∏è Nom du sch√©ma PostgreSQL/Supabase (sera cr√©√© automatiquement)
   * Changez si vous voulez un autre nom que 'psm_root'
   */
  schema: 'psm_root',

  /**
   * üì¶ Taille des batches pour les INSERT (ajustez selon la m√©moire)
   * - 100: s√ªr mais lent
   * - 500: bon √©quilibre
   * - 1000: rapide mais peut planter avec beaucoup de donn√©es
   */
  batchSize: 100,

  /**
   * üîç Options avanc√©es
   */
  options: {
    /**
     * Supprimer les tables existantes avant cr√©ation (true = recommand√©)
     */
    dropExistingTables: true,

    /**
     * Ajouter des commentaires explicatifs dans le SQL
     */
    addComments: true,

    /**
     * Cr√©er les index automatiquement (peut √™tre lent sur gros volumes)
     */
    createIndexes: false
  }
};

// ============================================
// FONCTIONS UTILITAIRES
// ============================================

/**
 * üéØ MOTS R√âSERV√âS POSTGRESQL
 * =============================
 * Liste compl√®te des mots-cl√©s r√©serv√©s par PostgreSQL.
 * Si un nom de colonne correspond √† l'un de ces mots,
 * un underscore sera ajout√© devant pour √©viter les erreurs SQL.
 */
const RESERVED_KEYWORDS = new Set([
  'all', 'analyse', 'analyze', 'and', 'any', 'array', 'as', 'asc', 'asymmetric',
  'authorization', 'binary', 'both', 'case', 'cast', 'check', 'collate', 'collation',
  'column', 'concurrently', 'constraint', 'create', 'cross', 'current_catalog',
  'current_date', 'current_role', 'current_schema', 'current_timestamp', 'current_user',
  'default', 'deferrable', 'desc', 'distinct', 'do', 'else', 'end', 'except', 'false',
  'fetch', 'for', 'foreign', 'freeze', 'from', 'full', 'grant', 'group', 'having',
  'ilike', 'in', 'initially', 'inner', 'intersect', 'into', 'is', 'isnull', 'join',
  'lateral', 'leading', 'left', 'like', 'limit', 'localtime', 'localtimestamp',
  'natural', 'not', 'notnull', 'null', 'offset', 'on', 'only', 'or', 'order', 'outer',
  'overlaps', 'placing', 'primary', 'references', 'returning', 'right', 'select',
  'session_user', 'similar', 'some', 'symmetric', 'table', 'tablesample', 'then',
  'to', 'trailing', 'true', 'union', 'unique', 'user', 'using', 'variadic', 'verbose',
  'when', 'where', 'window', 'with'
]);

/**
 * üßπ NETTOYAGE ET NORMALISATION DES NOMS
 * ======================================
 * Transforme les noms de colonnes/tables Fibery en noms PostgreSQL valides
 *
 * TRANSFORMATIONS APPLIQU√âES :
 * - √©, √†, √ß, etc. ‚Üí e, a, c (suppression des accents)
 * - "L'important" ‚Üí "l_important" (apostrophes)
 * - "Ma-super colonne" ‚Üí "ma_super_colonne" (espaces/tirets)
 * - "2nd_colonne" ‚Üí "_2nd_colonne" (commence par chiffre)
 * - "order" ‚Üí "_order" (mot r√©serv√© PostgreSQL)
 * - Maximum 63 caract√®res (limite PostgreSQL)
 *
 * @param {string} name - Nom original de la colonne/table
 * @returns {string} - Nom nettoy√© compatible PostgreSQL
 */
function sanitizeName(name) {
  if (!name) return 'unnamed';

  // √âtape 1: Normalisation Unicode (d√©compose les caract√®res accentu√©s)
  let clean = name
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '');

  // √âtape 2: Remplacer les caract√®res probl√©matiques par underscore
  clean = clean.replace(/[''`]/g, '_');  // Apostrophes
  clean = clean.replace(/[\s\-\./]+/g, '_');  // Espaces, tirets, points, slashes

  // √âtape 3: Garder seulement les caract√®res alphanum√©riques + underscore
  clean = clean.replace(/[^a-zA-Z0-9_]/g, '');

  // √âtape 4: Minuscules
  clean = clean.toLowerCase();

  // √âtape 5: Nettoyer les underscores
  clean = clean.replace(/_+/g, '_');  // Multiples ‚Üí simple
  clean = clean.replace(/^_+|_+$/g, '');  // D√©but/fin

  // √âtape 6: V√©rifications sp√©ciales
  if (!clean) clean = 'unnamed';  // Si vide apr√®s nettoyage
  if (/^[0-9]/.test(clean)) clean = '_' + clean;  // Commence par chiffre
  if (RESERVED_KEYWORDS.has(clean)) clean = '_' + clean;  // Mot r√©serv√©

  // √âtape 7: Limite de longueur PostgreSQL
  if (clean.length > 63) {
    clean = clean.substring(0, 63);
  }

  return clean;
}

/**
 * üîÆ D√âTECTION AUTOMATIQUE DES TYPES POSTGRESQL
 * =============================================
 * Analyse une valeur et d√©termine le type PostgreSQL le plus appropri√©
 *
 * ALGORITHME DE D√âTECTION :
 * ========================
 * 1. Valeurs nulles/vides ‚Üí TEXT (par d√©faut)
 * 2. Formats sp√©cifiques ‚Üí types pr√©cis
 * 3. Patterns regex ‚Üí types optimis√©s
 * 4. Fallback ‚Üí TEXT (universel)
 *
 * @param {any} value - Valeur √† analyser
 * @returns {string} - Type PostgreSQL (UUID, INTEGER, BOOLEAN, etc.)
 */
function guessPostgresType(value) {
  // Cas 1: Valeurs nulles ou vides
  if (value === null || value === undefined || value === '') {
    return 'TEXT'; // Type par d√©faut pour les valeurs manquantes
  }

  const str = String(value).trim();

  // Cas 2: Bool√©ens (diff√©rentes notations accept√©es)
  const booleanValues = ['true', 'false', '1', '0', 'yes', 'no', 'y', 'n'];
  if (booleanValues.includes(str.toLowerCase())) {
    return 'BOOLEAN';
  }

  // Cas 3: UUID (format standard UUID v4)
  // Ex: "d47ec620-2190-11ef-910c-f1df4955273f"
  const uuidPattern = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
  if (uuidPattern.test(str)) {
    return 'UUID'; // Type natif PostgreSQL, plus efficace que TEXT
  }

  // Cas 4: Entiers (n√©gatifs ou positifs)
  // Ex: "-123", "456", "0"
  if (/^-?\d+$/.test(str)) {
    return 'INTEGER';
  }

  // Cas 5: D√©cimaux (avec point d√©cimal)
  // Ex: "123.45", "-67.89"
  if (/^-?\d+\.\d+$/.test(str)) {
    return 'NUMERIC(12,2)'; // Pr√©cision fixe pour les prix, montants
  }

  // Cas 6: Dates au format ISO (YYYY-MM-DD)
  // Ex: "2024-06-03"
  if (/^\d{4}-\d{2}-\d{2}$/.test(str)) {
    return 'DATE'; // Date sans heure
  }

  // Cas 7: Dates avec heure (format ISO 8601)
  // Ex: "2024-06-03T10:05:39.625Z", "2024-06-03T10:05:39"
  if (/^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}/.test(str)) {
    return 'TIMESTAMPTZ'; // Date + heure + timezone
  }

  // Cas 8: Par d√©faut - texte (compatible avec tout)
  return 'TEXT';
}

/**
 * üõ°Ô∏è √âCHAPP√âMENT DES VALEURS POUR SQL
 * ====================================
 * Convertit une valeur JavaScript en format SQL s√ªr
 *
 * R√àGLES D'√âCHAPP√âMENT :
 * ====================
 * - NULL/undefined/vide ‚Üí NULL SQL
 * - BOOLEAN ‚Üí TRUE/FALSE SQL (converti depuis plusieurs formats)
 * - Nombres ‚Üí valeur num√©rique directe (validation NaN)
 * - Textes ‚Üí entre apostrophes, avec √©chappement des apostrophes
 *
 * @param {any} value - Valeur √† √©chapper
 * @param {string} type - Type PostgreSQL de la colonne
 * @returns {string} - Valeur format√©e pour SQL
 */
function escapeSQLValue(value, type) {
  // Cas 1: Valeurs nulles ou manquantes
  if (value === null || value === undefined || value === '') {
    return 'NULL';
  }

  const str = String(value);

  // Cas 2: Bool√©ens (conversion depuis plusieurs formats)
  if (type === 'BOOLEAN') {
    const lower = str.toLowerCase();
    if (['true', '1', 'yes', 'y'].includes(lower)) return 'TRUE';
    if (['false', '0', 'no', 'n'].includes(lower)) return 'FALSE';
    return 'NULL'; // Format non reconnu
  }

  // Cas 3: Nombres (entiers et d√©cimaux)
  if (type === 'INTEGER' || type.startsWith('NUMERIC')) {
    const num = parseFloat(str);
    return isNaN(num) ? 'NULL' : String(num);
  }

  // Cas 4: Textes, UUIDs, dates (tous entre apostrophes)
  if (type === 'UUID' || type === 'DATE' || type === 'TIMESTAMPTZ' || type === 'TEXT') {
    // √âchapper les apostrophes : ' ‚Üí ''
    const escaped = str.replace(/'/g, "''");
    return `'${escaped}'`;
  }

  // Cas 5: Type non g√©r√© (fallback)
  return 'NULL';
}

/**
 * üìÑ PARSING DES FICHIERS CSV FIBERY
 * ===================================
 * Lit et analyse un fichier CSV export√© depuis Fibery
 *
 * FORMAT ATTENDU :
 * ===============
 * - S√©parateur : virgule (,)
 * - Guillemets : doubles pour les valeurs contenant des virgules
 * - Encodage : UTF-8 (support des caract√®res sp√©ciaux)
 * - Ligne 1 : en-t√™tes de colonnes
 * - Lignes 2+ : donn√©es
 *
 * @param {string} filePath - Chemin vers le fichier CSV
 * @returns {Object} - { headers: [...], rows: [...] }
 */
function parseCSV(filePath) {
  const content = fs.readFileSync(filePath, 'utf8');
  const lines = content.split('\n').filter(line => line.trim());

  if (lines.length === 0) return { headers: [], rows: [] };

  // √âtape 1: Parser la ligne d'en-t√™te
  const headers = parseCSVLine(lines[0]);

  // √âtape 2: Parser les lignes de donn√©es
  const rows = [];
  for (let i = 1; i < lines.length; i++) {
    const values = parseCSVLine(lines[i]);
    if (values.length === headers.length) {
      const row = {};
      headers.forEach((header, idx) => {
        row[header] = values[idx];
      });
      rows.push(row);
    }
  }

  return { headers, rows };
}

/**
 * üîß PARSING D'UNE LIGNE CSV
 * ==========================
 * Analyse une ligne CSV en g√©rant correctement les guillemets
 *
 * GESTION DES GUILLEMETS :
 * =======================
 * - "valeur" : valeur simple
 * - "valeur avec,virgule" : virgule √† l'int√©rieur des guillemets
 * - "valeur avec""guillemets" : guillemets doubl√©s √† l'int√©rieur
 * - valeur,sans,guillemets : valeurs multiples
 *
 * @param {string} line - Ligne CSV √† parser
 * @returns {string[]} - Tableau des valeurs
 */
function parseCSVLine(line) {
  const values = [];
  let current = '';
  let inQuotes = false;

  for (let i = 0; i < line.length; i++) {
    const char = line[i];
    const nextChar = line[i + 1];

    // Cas 1: D√©but de guillemets
    if (char === '"' && !inQuotes) {
      inQuotes = true;

    // Cas 2: Guillemets doubl√©s (√©chappement)
    } else if (char === '"' && inQuotes && nextChar === '"') {
      current += '"';  // Ajouter un seul guillemet
      i++; // Sauter le guillemet suivant

    // Cas 3: Fin de guillemets
    } else if (char === '"' && inQuotes) {
      inQuotes = false;

    // Cas 4: S√©parateur (virgule) en dehors des guillemets
    } else if (char === ',' && !inQuotes) {
      values.push(current.trim());
      current = '';

    // Cas 5: Caract√®re normal
    } else {
      current += char;
    }
  }

  // Ajouter la derni√®re valeur
  values.push(current.trim());
  return values;
}

// ============================================
// G√âN√âRATION SQL
// ============================================

/**
 * G√©n√®re le SQL pour une base de donn√©es
 */
function generateSQLForDatabase(dbFolder, dbName) {
  console.log(`\nüìä Traitement: ${dbName}`);
  
  // Trouver le fichier CSV principal
  const files = fs.readdirSync(dbFolder);
  const csvFile = files.find(f => f.endsWith('.csv'));
  
  if (!csvFile) {
    console.log(`  ‚ö†Ô∏è  Aucun fichier CSV trouv√©, skip`);
    return '';
  }
  
  const csvPath = path.join(dbFolder, csvFile);
  console.log(`  ‚Üí CSV: ${csvFile}`);
  
  // Parser le CSV
  const { headers, rows } = parseCSV(csvPath);
  
  if (headers.length === 0 || rows.length === 0) {
    console.log(`  ‚ö†Ô∏è  CSV vide, skip`);
    return '';
  }
  
  console.log(`  ‚Üí ${headers.length} colonnes, ${rows.length} lignes`);
  
  // Nettoyer le nom de la table
  const tableName = sanitizeName(dbName);
  console.log(`  ‚Üí Table SQL: ${CONFIG.schema}.${tableName}`);
  
  // D√©tecter les types de colonnes
  const columns = {};
  const hasIdColumn = headers.some(h => sanitizeName(h) === 'id');
  
  for (const header of headers) {
    const cleanHeader = sanitizeName(header);
    
    // √âchantillonner 10 valeurs pour deviner le type
    const sampleValues = rows.slice(0, 10).map(row => row[header]);
    const types = sampleValues.map(v => guessPostgresType(v));
    
    // Type majoritaire
    const typeCounts = {};
    types.forEach(t => typeCounts[t] = (typeCounts[t] || 0) + 1);
    const majorityType = Object.keys(typeCounts).reduce((a, b) => 
      typeCounts[a] > typeCounts[b] ? a : b
    );
    
    columns[header] = {
      sqlName: cleanHeader,
      type: majorityType
    };
  }
  
  // G√©n√©rer le SQL
  let sql = '';
  
  // CREATE TABLE
  sql += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`;
  sql += `-- Table: ${tableName}\n`;
  sql += `-- Source: ${dbName}\n`;
  sql += `-- Lignes: ${rows.length}\n`;
  sql += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n`;
  
  sql += `DROP TABLE IF EXISTS ${CONFIG.schema}.${tableName} CASCADE;\n\n`;
  
  sql += `CREATE TABLE ${CONFIG.schema}.${tableName} (\n`;
  
  // Si le CSV a d√©j√† une colonne "Id", on l'utilise comme PK
  // Sinon, on cr√©e un id auto-g√©n√©r√©
  if (hasIdColumn) {
    // L'Id Fibery sera la cl√© primaire
    sql += `  -- Colonnes (Id Fibery = Primary Key)\n`;
  } else {
    // Cr√©er un id auto-g√©n√©r√©
    sql += `  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n`;
    sql += `  \n`;
    sql += `  -- Colonnes\n`;
  }
  
  // Colonnes
  const columnDefs = Object.entries(columns).map(([original, col]) => {
    // Si c'est la colonne Id et qu'elle existe, la marquer comme PK
    if (hasIdColumn && col.sqlName === 'id') {
      return `  ${col.sqlName} UUID PRIMARY KEY`;
    }
    return `  ${col.sqlName} ${col.type}`;
  });
  sql += columnDefs.join(',\n');
  
  // Ajout des colonnes de m√©tadonn√©es uniquement si pas d'Id Fibery
  if (!hasIdColumn) {
    sql += ',\n';
    sql += `  \n`;
    sql += `  -- M√©tadonn√©es\n`;
    sql += `  created_at TIMESTAMPTZ DEFAULT NOW(),\n`;
    sql += `  updated_at TIMESTAMPTZ DEFAULT NOW()\n`;
  } else {
    sql += '\n';
  }
  
  sql += `);\n\n`;
  
  // Commentaire
  sql += `COMMENT ON TABLE ${CONFIG.schema}.${tableName} IS 'Migr√© depuis Fibery: ${dbName} | ${rows.length} lignes';\n\n`;
  
  // INSERT par batch
  console.log(`  ‚Üí G√©n√©ration des INSERT (batch size: ${CONFIG.batchSize})...`);
  
  for (let i = 0; i < rows.length; i += CONFIG.batchSize) {
    const batch = rows.slice(i, i + CONFIG.batchSize);
    
    sql += `-- Batch ${Math.floor(i / CONFIG.batchSize) + 1}/${Math.ceil(rows.length / CONFIG.batchSize)}\n`;
    sql += `INSERT INTO ${CONFIG.schema}.${tableName} (`;
    
    // Noms de colonnes
    const colNames = Object.values(columns).map(c => c.sqlName);
    sql += colNames.join(', ');
    sql += `) VALUES\n`;
    
    // Valeurs
    const valueLines = batch.map(row => {
      const values = Object.entries(columns).map(([original, col]) => {
        return escapeSQLValue(row[original], col.type);
      });
      return `  (${values.join(', ')})`;
    });
    
    sql += valueLines.join(',\n');
    sql += ';\n\n';
  }
  
  console.log(`  ‚úÖ ${rows.length} lignes g√©n√©r√©es`);
  
  return sql;
}

// ============================================
// MAIN
// ============================================

function main() {
  console.log('‚îÅ'.repeat(80));
  console.log('üöÄ CSV TO SQL MIGRATOR - Fibery ‚Üí Supabase');
  console.log('‚îÅ'.repeat(80));
  console.log(`üìÇ Dossier source: ${CONFIG.importantDir}`);
  console.log(`üìÑ Fichier SQL: ${CONFIG.outputSQL}`);
  console.log(`üóÇÔ∏è  Sch√©ma PostgreSQL: ${CONFIG.schema}`);
  console.log('‚îÅ'.repeat(80));
  
  // V√©rifier que le dossier existe
  if (!fs.existsSync(CONFIG.importantDir)) {
    console.error(`‚ùå ERREUR: Dossier introuvable: ${CONFIG.importantDir}`);
    console.log('\nüí° Modifiez la variable importantDir dans le script');
    process.exit(1);
  }
  
  // Lister les sous-dossiers (bases de donn√©es)
  const databases = fs.readdirSync(CONFIG.importantDir)
    .filter(name => {
      const fullPath = path.join(CONFIG.importantDir, name);
      return fs.statSync(fullPath).isDirectory();
    })
    .sort();
  
  console.log(`\nüìä ${databases.length} bases de donn√©es trouv√©es:\n`);
  databases.forEach((db, idx) => {
    console.log(`  ${idx + 1}. ${db}`);
  });
  
  // G√©n√©rer le header SQL
  let fullSQL = '';
  fullSQL += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`;
  fullSQL += `-- MIGRATION FIBERY ‚Üí SUPABASE\n`;
  fullSQL += `-- G√©n√©r√© le: ${new Date().toISOString()}\n`;
  fullSQL += `-- Bases: ${databases.length}\n`;
  fullSQL += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n`;
  fullSQL += `-- Cr√©ation du sch√©ma\n`;
  fullSQL += `CREATE SCHEMA IF NOT EXISTS ${CONFIG.schema};\n`;
  fullSQL += `SET search_path TO ${CONFIG.schema}, public;\n\n`;
  fullSQL += `-- Extension UUID\n`;
  fullSQL += `CREATE EXTENSION IF NOT EXISTS "uuid-ossp";\n\n`;
  
  // Traiter chaque base
  for (const db of databases) {
    const dbFolder = path.join(CONFIG.importantDir, db);
    const sql = generateSQLForDatabase(dbFolder, db);
    fullSQL += sql;
  }
  
  // Footer
  fullSQL += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`;
  fullSQL += `-- FIN DE LA MIGRATION\n`;
  fullSQL += `-- ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n`;
  fullSQL += `RESET search_path;\n`;
  
  // Sauvegarder
  fs.writeFileSync(CONFIG.outputSQL, fullSQL, 'utf8');
  
  const fileSize = (fs.statSync(CONFIG.outputSQL).size / 1024).toFixed(1);
  
  console.log('\n‚îÅ'.repeat(80));
  console.log('‚úÖ MIGRATION SQL G√âN√âR√âE !');
  console.log('‚îÅ'.repeat(80));
  console.log(`üìÑ Fichier: ${CONFIG.outputSQL}`);
  console.log(`üìä Taille: ${fileSize} KB`);
  console.log(`\nüöÄ PROCHAINES √âTAPES:`);
  console.log(`  1. Ouvrez Supabase SQL Editor`);
  console.log(`  2. Copiez-collez le contenu de ${CONFIG.outputSQL}`);
  console.log(`  3. Cliquez "Run" pour ex√©cuter`);
  console.log('‚îÅ'.repeat(80));
}

// Lancer le programme
try {
  main();
} catch (error) {
  console.error('\n‚ùå ERREUR:', error.message);
  console.error(error.stack);
  process.exit(1);
}